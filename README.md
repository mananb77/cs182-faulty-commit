# Faulty Commit Classification with Binary Classifiers

This project implements and evaluates binary classification models to predict whether a commit is faulty or not. It includes data preprocessing, baseline and neural models, evaluation using precision-recall curves and average precision (AP), and support for trivial and advanced baselines.

This repository was developed as part of a machine learning project, and contains an end-to-end pipeline from data loading and model training to offline evaluation and submission packaging. This machine learning project was developed for Data C182 Fall 2024: Deep Neural Networks at UC Berkeley.

**Project spec**: https://docs.google.com/document/d/1erKfrMXIY_JkPB_648wyaTXP89Llo4MyD68l_pZRwZo/edit?tab=t.0#heading=h.i522cvq4jmw

---

## ğŸš€ Features

- Offline evaluation using precision-recall curves, F1 scores, and Average Precision (AP)
- Implementation of trivial baseline classifiers:
  - AlwaysPositiveBinaryClassifier
  - AlwaysNegativeBinaryClassifier
  - RandomBinaryClassifier
- Neural models including:
  - Single-layer feedforward neural network (SingleLayerNN)
  - Custom multilayer architectures to beat baseline performance
- Utilities for loading and preprocessing commit-level and developer-level metadata
- Colab integration and Gradescope-compatible submission pipeline

---

## ğŸ—‚ï¸ Project Structure
.
â”œâ”€â”€ consts.py                            # Project-wide constants

â”œâ”€â”€ final_project.ipynb                  # Main Colab notebook for training, evaluation, and submission

â”œâ”€â”€ evaluation/

â”‚   â””â”€â”€ offline_eval.py                  # Offline evaluation pipeline implementation (predict_samples, compute_eval_metrics)

â”œâ”€â”€ modeling/

â”‚   â”œâ”€â”€ model_interface.py              # Defines the base model interface

â”‚   â”œâ”€â”€ model_random.py                 # Contains RandomBinaryClassifier

â”‚   â”œâ”€â”€ model_single_layer.py          # Implementation of SingleLayerNN

â”‚   â””â”€â”€ trivial_models.py              # AlwaysPositive and AlwaysNegative classifiers

â”œâ”€â”€ utils/

â”‚   â””â”€â”€ utils.py                        # Utility functions (e.g., dataloader creation, preprocessing helpers)

â”œâ”€â”€ dataloader/

â”‚   â”œâ”€â”€ fault_csv_dataset.py           # Custom PyTorch dataset class for loading commit data

â”‚   â””â”€â”€ preprocess.py                  # Data preprocessing logic (fit/transform for features)

â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ raw/                           # Contains raw datasets (e.g., user_meta.csv)

â”‚   â””â”€â”€ split/                         # Pre-split train/val/test datasets

â”œâ”€â”€ submission/

â”‚   â””â”€â”€ generate_submission.py         # Script to zip files and generate Gradescope-compatible submission

â””â”€â”€ requirements.txt                   # Python dependencies

---

## ğŸ“ˆ Offline Evaluation Details

The evaluation pipeline computes:

- Precision-Recall Curve using `sklearn.metrics.precision_recall_curve`
- Average Precision using `sklearn.metrics.average_precision_score`
- Operating point (threshold) that maximizes F1 score
- Precision/Recall/F1 metrics at arbitrary thresholds

All results are wrapped in structured data classes (`PredictionMetadata`, `OperatingPointMetrics`, etc.).

---

## ğŸ§ª Trivial Baselines

Implemented in `trivial_models.py` and `model_random.py`:

- **AlwaysPositiveBinaryClassifier**: always predicts the positive class
- **AlwaysNegativeBinaryClassifier**: always predicts the negative class
- **RandomBinaryClassifier**: predicts randomly based on a biased coin

Use these to establish performance baselines and debug the evaluation pipeline.

---

## ğŸ§  Neural Models

- **SingleLayerNN**: simple feedforward model with a single linear layer
- **Improved Model**: optional multi-layer architecture that aims to exceed `0.025` AP on the test set

---

## ğŸ“Œ Acknowledgements
This project was developed for educational purposes as part of a machine learning course. Special thanks to the course staff for designing the pipeline and providing a great learning experience.
